---
title: "Can You Beat the Stock Market Using Machine Learning?"
subtitle: "Spring 2024"
author: "Matthew Zimmermann"
number-sections: false
format:
  html:
    theme: default
    rendering: embed-resources
    code-fold: true
    code-tools: true
    toc: true
  pdf: default
jupyter: python3
---


![](https://soundsandcolours.com/static/2019/09/stocks-in-latin-america.jpg){fig-alt="A photo of price action from a stock."}

Since the beggining of the financial markets, people have been trying to find every possible way to maximize a return on their investments. The golden question of, “can the stock market be predicted?” has been asked and studied for a long time. It seemed as if predicting the stock market was
an impossible feat, and can still very much be so, however, with the introduction of machine learning into the financial world, it seems that the answer is getting closer and closer to being solved. Machine learning is revolutinizing the financial world, and is allowing investors to make more informed investment decisions in a space that is extremely complex. In this analysis, I will try to answer this question to the best of my abilities. I have created two models which will be compared and utilized to try and outperform a traditional buy and hold strategy, by using the models predicted values to make more informed and frequent trades.

# Data Collection
## Importing Packages
First, we must import all of the required packages and specify the stock we will be analyzing. This program can be ran using any stock available on Yahoo Finance, however, for this analysis we will be looking specifically at Apple Inc. To run this analysis using a different stock, the variable 'tick' can be changed to any ticker.
```{python}
#| code-fold: false
# Importing all required packages
import numpy as np
import pandas as pd
import yfinance as yf
import plotly.graph_objects as go
import math
import matplotlib.pyplot as plt
import ipywidgets as widgets
from IPython.display import display
from datetime import datetime
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestRegressor
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.stattools import adfuller
import tensorflow as tf
from keras.layers import Dense,LSTM,Dropout,Flatten
from keras import Sequential
from keras import backend as K
from pmdarima.arima import auto_arima
from sklearn.metrics import mean_squared_error, mean_absolute_error, precision_score

# Ignoring warnings and output log
import warnings
warnings.filterwarnings('ignore')
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'

# Specifying the ticker and balance
tick = 'AAPL'
initial_balance = 10000
```

## Gathering the Data
The data that I will be using is stock data gathered from Yahoo Finance and is downloaded using the YFinance package. This data includes the Open, High, Low, Close, Adj. Close, and Volume for the given stock from 2018-2024. For later use in the analysis, I added a 'Return' column which calculates the return of that stock for each day available in the dataset.
```{python}
def create_dataset(ticker):
    # Gather data, preprocess, and add return column
    df = yf.download(ticker, progress=False)
    df.index = pd.to_datetime(df.index)
    df = df[df.index >= '2018-01-01']
    df = df[df.index <= '2024-04-18']
    df['Return'] = (df['Adj Close'] - df['Open']) / df['Open']
    return df

# Calling the function
# Assigning the output as a variable to be called in later functions
data = create_dataset(tick)
data.head(5)
```

# Visualizing the Data
Before training any models I wanted to be able to visualize the stock in a way that you would see on the average trading platform along with some extra technical indicators. The chart gives you the option to toggle on and off two seperate moving averages, which are a smoothed trend line that represents the average value of a series of data points over a specified period, helping to identify overall direction. The data points are displayed using 'candlesticks', which visualize multiple datapoints related to the stock price over a given timeframe. These datapoints include the open, close, high, and low over a month-long timeframe.
```{python}
#| label: candlestick-chart
#| fig-cap: "Figure 1: Candlestick Chart"
def candlestick_chart(df, ticker):
    # Create both 50 and 200 day moving average
    df['MA50'] = df['Close'].rolling(window=50).mean()
    df['MA200'] = df['Close'].rolling(window=200).mean()

    # Group into monthly for the candlesticks
    monthly_data = df.resample('M').agg({
        'Open': 'first',
        'High': 'max',
        'Low': 'min',
        'Close': 'last',
        'Volume': 'sum'
    })

    # Create trace for the candlesticks
    candlestick = go.Candlestick(x=monthly_data.index,
                    open=monthly_data['Open'],
                    high=monthly_data['High'],
                    low=monthly_data['Low'],
                    close=monthly_data['Close'],
                    name='Candlestick')

    #Create trace for moving averages
    ma_50 = go.Scatter(x=df.index, y=df['MA50'], mode='lines', name='50-Day MA', line=dict(color='grey'), visible = False)
    ma_200 = go.Scatter(x=df.index, y=df['MA200'], mode='lines', name='200-Day MA', line=dict(color='black'), visible = False)

    # Create buttons to toggle moving averages
    button_50 = dict(label='50-Day MA', method='update', args=[{'visible': [True, True, False]}, {'title': f'({ticker}) - 50-Day MA'}])
    button_200 = dict(label='200-Day MA', method='update', args=[{'visible': [True, False, True]}, {'title': f'({ticker}) - 200-Day MA'}])
    button_both = dict(label='Both', method='update', args=[{'visible': [True, True, True]}, {'title': f'({ticker})'}])
    button_none = dict(label='None', method='update', args=[{'visible': [True, False, False, False]}, {'title': f'({ticker})'}])

    # Creating button menu, specifying location of the menu
    updatemenus = list([
        dict(active=3,
            buttons=[button_50, button_200, button_both, button_none],
            x=1.0,
            y=1.0,
            xanchor='right',
            yanchor='top',
            pad=dict(t=0, r=10),
            showactive=True)
    ])


    # Updating layout of figure
    layout = dict(title=f'{ticker} Stock Price',
                xaxis_title='Date',
                yaxis_title='Stock Price ($)',
                updatemenus=updatemenus)

    # Create and display figure
    fig = go.Figure(data=[candlestick, ma_50, ma_200], layout=layout)
    fig.show()

# Calling the function
candlestick_chart(data, tick)
```

:::{.callout-note}
'Candlesticks' are used in @candlestick_chart. More details about candlesticks can be found [here](https://www.investopedia.com/trading/candlestick-charting-what-is-it/).
:::

## Plotting Yearly Returns
```{python}
#| label: yearly-returns
#| fig-cap: "Figure 2: Yearly Return Plot"
def yearly_returns(df, ticker):
    yearly_returns = []

    # Group data and calculate yearly return
    for year in range(df.index.min().year, df.index.max().year + 1):
        start_date = df[df.index.year == year].index.min()
        end_date = df[df.index.year == year].index.max()
        year_data = df[(df.index >= start_date) & (df.index <= end_date)]
        start_price = year_data.iloc[0]['Open']
        end_price = year_data.iloc[-1]['Close']
        yearly_return = ((end_price - start_price) / start_price) * 100
        yearly_return = round(yearly_return, 2)
        yearly_returns.append((year, yearly_return))

    # Plot yearly returns
    yearly_returns_df = pd.DataFrame(yearly_returns, columns=['Year', 'Yearly_Return'])
    bar_trace = go.Bar(x=yearly_returns_df['Year'], y=yearly_returns_df['Yearly_Return'],
                       marker=dict(color='skyblue'))

    layout = go.Layout(title=f'Yearly Returns of {ticker} (2018-2024)',
                       xaxis=dict(title='Year'),
                       yaxis=dict(title='Yearly Return (%)'))

    fig = go.Figure(data=[bar_trace], layout=layout)
    fig.show()

yearly_returns(data, tick)
```

@yearly-returns shows us the yearly return each year of Apple stock. We can see that since 2018, Apple has been a very good investment for long term holders. The only negative yearly returns that Apple has had since 2018, has been in 2018 and 2022, giving a negative return of -7.3% and -26.94% respectively. However, despite those negative returns, every other year has shown incredible gains, and has regained more than what was lost. The highest yearly return of Apple stock since 2018 was in 2019, where the stock showed a postive 89.59% gain, following that up with a 79.17% gain in 2020. At the time of making this analysis, we are still in the middle of 2024, so we cannot truly take into consideration the yearly return of 2024 shown here, however we can still keep it in mind that at the time of making this analysis, Apple is currently at a -2.59% return in 2024.

# Model Creation
In order to try and increase investment returns, we must first train a model that accurately predicts the stock's closing prices. To do this, I trained two seperate models to see which one is more accurate. Both models were trained on data from January 2018 to February 2023, and tested with data from February 2023 to February 2024.The models that I used for this analysis are Long Short-Term Memory (LSTM) and Auto-Regressive Integrated Moving Average (ARIMA).

**LSTM**: is a type of neural network that retains important information over long sequences, enabling it to make  predictions by selectively storing and forgetting nformation as needed.

**ARIMA**: looks at past patterns in the data to make an educated forecast of the future values.

## Stationary Test 
In order for the ARIMA model to be created, the time series data must be stationary. This means that the mean and standard deviation of the data must not vary across time. We can visualize the mean and standard deviation along with running a hypothesis test to see if the data is stationary or not.
```{python}
#| label: stat-test
#| fig-cap: "Figure 3: Stationarity Test"
# Test if the data is stationary and visualize it
def test_stationarity(timeseries):
    rolmean = timeseries.rolling(12).mean()
    rolstd = timeseries.rolling(12).std()
    plt.figure(figsize=(15,5))
    plt.plot(timeseries,color='blue',label='Original')
    plt.plot(rolmean,color='red',label='Rolling Mean')
    plt.plot(rolstd, color='black', label = 'Rolling Std')
    plt.legend(loc='best')
    plt.title('Rolling Mean and Standard Deviation')
    plt.show(block=False)
    print("Results of dickey fuller test")
    adft = adfuller(timeseries,autolag='AIC')
    output = pd.Series(adft[0:4],index=['Test Statistics','p-value','No. of lags used','Number of observations used'])
    print(output)
    is_stationary = adft[1] < 0.05
    return is_stationary

test_stationarity(data['Close'])
```

The results of @stat-test shows that the data is not stationary. This can be seen where the rolling mean and standard deviation is not constant over the timeframe of the data. The p-value of the hypothesis test is greater than the confidence interval of 0.05, indicating that we cannot conclude that the data is stationary. So now we must difference the data to make it stationary so the ARIMA model can run properly.

## ARIMA model
When creating the model, the use of the auto_arima() function allows the data to be automatically differenced along with the optimal p,d,q values to be found. These values control the autoregressive, differencing, and moving average components of the model, respectively.
```{python}
#| label: arima-model
#| fig-cap: "Figure 4: ARIMA Model"
def create_arima(df, ticker):
   # Split data into training and testing sets
   model_name = "ARIMA"
   df_train = df[df.index < '2023-02-02']
   df_valid = df[df.index >= '2023-02-02']
   train = df_train['Close'].values
   test = df_valid['Close'].values

   # Find the optimal p,d,q and assign it to the model
   model = auto_arima(train, start_p=0, start_q=0, test='adf', max_p=5, max_q=5,
                   m=1, d=None, seasonal=False,
                   start_P=0, D=0,
                   trace=False, error_action='ignore',
                   suppress_warnings=True, stepwise=True)
   
   p, d, q = model.order
   optimal_values = p,d,q
   history = [x for x in train]
   predictions = list()

   # Train the model using optimal p,d,q values
   for t in range(len(df_valid)):
      model = ARIMA(history, order=(optimal_values))
      model_fit = model.fit()
      output = model_fit.forecast()
      yhat = output[0]
      predictions.append(yhat)
      obs = test[t]
      history.append(obs)

   #Calculate accuracy of model
   rmse_arima = math.sqrt(mean_squared_error(test, predictions))
   threshold = 1
   actual_prices = df_valid['Close']
   percentage_changes = ((predictions - actual_prices) / actual_prices) * 100
   correct_predictions = np.sum(np.abs(percentage_changes) <= threshold)
   rate_arima = (correct_predictions / len(actual_prices)) * 100

   # Display model results
   fig = go.Figure()
   fig.update_layout(xaxis_title="Date", yaxis_title="Stock Price ($)", title = f"Actual vs. Forecasted Closing Price of {ticker} (ARIMA)")
   fig.add_trace(go.Scatter(x=df_train.index,y=df_train.Close,name='Training Data'))
   fig.add_trace(go.Scatter(x=df_valid.index,y=df_valid.Close,name='Testing Data'))
   fig.add_trace(go.Scatter(x=df_valid.index,y=predictions,name='Forecasted Data'))
   fig.show()

   # Print accuracy rates of model
   print("Hit Rate: %.2f%%" % rate_arima)
   print('Test RMSE: %.3f' % rmse_arima)

   rmse_arima = round(rmse_arima, 2)
   rate_arima = round(rate_arima, 2)
   return predictions, test, rmse_arima, rate_arima, model_name

arima_variables = create_arima(data, tick)
```

To analyze the accuracy of the model, I looked at two different things. The Root Mean Squared Error (RMSE), and the 'Hit-Rate'. The RMSE tells us how close the predicted values were to the actual closing price, on average, in dollars. The 'Hit-Rate' tells us the percentage of times the predicted values fell within 1% of the actual closing price. As we see in @arima-model, this model was off by approximately $`{python} arima_variables[2]`, on average, and fell within 1% of the actual closing price about `{python} arima_variables[3]`% of the time.


## LSTM model
```{python}
#| label: lstm-model
#| fig-cap: "Figure 5: LSTM Model"
def create_lstm(df, ticker):
    # Splitting data into training and testing sets
    model_name = str("LSTM")
    df_train = df[df.index < '2023-02-02']
    df_valid = df[df.index >= '2023-02-02']
    train_lstm = df_train['Close'].values
    test_lstm = df_valid['Close'].values

    # Pre-process data for LSTM model; Scaling and reshaping data
    scaler = MinMaxScaler(feature_range=(0,1))
    training_values = np.reshape(train_lstm,(len(train_lstm),1))
    test_values = np.reshape(test_lstm, (len(test_lstm), 1))
    scaled_training_values = scaler.fit_transform(training_values)
    scaled_test_values = scaler.transform(test_values)

    # Assigning training values to the training data
    x_train = scaled_training_values[:-1]
    y_train = scaled_training_values[1:]

    # Reshape the data for LSTM
    x_train = np.reshape(x_train, (x_train.shape[0], 1, 1))

    # Creating, compiling, training the model
    model = Sequential()
    model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))
    model.add(LSTM(50, return_sequences=False))
    model.add(Dense(25))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mean_squared_error')
    model.fit(x_train, y_train, epochs=25, batch_size=50, verbose=0)

    # Make predictions on the test data
    predicted_price_scaled = model.predict(scaled_test_values[:-1])

    # Inverse transform the predicted values
    predicted_price = scaler.inverse_transform(predicted_price_scaled)
    predicted_price = np.squeeze(predicted_price)

    # Plotting the model results
    fig = go.Figure()
    fig.update_layout(xaxis_title="Date", yaxis_title="Stock Price ($)", title = f"Actual vs. Forecasted Closing Price of {ticker} (LSTM)")
    fig.add_trace(go.Scatter(x=df_train.index, y=df_train.Close, name='Training Data'))
    fig.add_trace(go.Scatter(x=df_valid.index, y=df_valid.Close, name='Testing Data'))
    fig.add_trace(go.Scatter(x=df_valid.index[:-1], y=predicted_price, name='Forecasted Data'))
    fig.show()

    # Calculate the RMSE
    rmse_lstm = math.sqrt(mean_squared_error(test_lstm[1:], predicted_price))

    # Calculate the hit rate
    threshold = 1
    actual_prices = df_valid['Close'].values[1:]
    percentage_changes = ((predicted_price - actual_prices) / actual_prices) * 100
    correct_predictions = np.sum(np.abs(percentage_changes) <= threshold)
    rate_lstm = (correct_predictions / len(actual_prices)) * 100

    rmse_lstm = round(rmse_lstm, 2)
    rate_lstm = round(rate_lstm, 2)

    print("Hit Rate: %.2f%%" % rate_lstm)
    print('Test RMSE: %.3f' % rmse_lstm)

    return predicted_price, test_lstm[1:], rmse_lstm, rate_lstm, model_name

lstm_variables = create_lstm(data, tick)
```

Similarly to the ARIMA model shown previously, we will be analyzing the LSTM model using the same forms of accuracy. The RMSE and 'Hit-Rate' of the model have been calculated and shown above. The LSTM model was off by approximately $`{python} lstm_variables[2]`, on average, and fell within 1% of the actual closing price about `{python} lstm_variables[3]`% of the time.

# Results of Analysis
In order to decide which model will be utilized to try and compete against the buy and hold strategy for a higher investment return, we must choose which form of accuracy is most important. Considering we are trying to maximimize how close we can get to predicting the actual closing price, the 'hit-rate' seems to be the best option for deciding which model to use in the simulation.

## Comparison of Models
```{python}
#| code-fold: false
def compare_models(arima_variables, lstm_variables):
    if arima_variables[3] > lstm_variables[3]:
        print("The ARIMA model is the more accurate model.")
        return arima_variables
    else:
        print("The LSTM model is the more accurate model.")
        return lstm_variables
    
chosen_model = compare_models(arima_variables, lstm_variables)
```

Now that we have concluded that the hit-rate is the most appropriate form of accuracy to choose the best model, we must compare the hit-rate of both models to see which one is higher. This function compares the two models to see which one has a higher hit-rate. The reason this must be calculated in the form of a function is that, if using a stock other than Apple, the ARIMA model may not be the more accurate model. This is why we must make this a function, so that the correct model gets chosen for each stock being tested.

## Utilizing Model Results to Increase Investment
Now that I have trained both models and selected the most accurate one, I must now utilize those predicted values to try and increase our investment returns. In order to do this I created a simulation which compares two strategies to see which one is more profitable. Both strategies will start at $10,000, run for approximately 1 year, and will not include tax or commissions on trades. The first strategy is a simple buy and hold strategy, which purchases the stock on day 1, and sells on the last day with no trades inbetween. The second strategy utilizes the predicted values to buy and sell according to what it predicts the stock will do. 
```{python}
#| code-fold: false
# Creating two trading strategies to compare
def buy_and_hold(initial_balance, closing_prices):
    # Find initial and ending closing price
    initial_price = closing_prices[0]
    final_price = closing_prices[-1]
    # Calculate num of shares and ending balance
    shares_bought = initial_balance / initial_price
    final_balance = shares_bought * final_price
    return final_balance


def model_trading_strategy(initial_balance, actual_prices, predictions):
    balance = initial_balance
    position_open = False
    buy_price = None
    shares = 0
    # Iterate through the predictions; buy and sell if next day is higher/lower than previous
    for i in range(1, len(predictions)):
        if predictions[i] > predictions[i - 1] and not position_open:
            buy_price = actual_prices[i-1]
            shares = balance / buy_price
            balance -= shares * buy_price
            position_open = True
        elif predictions[i] < predictions[i - 1] and position_open:
            sell_price = actual_prices[i-1]
            balance += shares * sell_price
            shares = 0
            position_open = False

    if position_open:  # Close position if still open at the end
        balance += shares * actual_prices[-1]

    return balance

# Call functions and display output
actual_prices = chosen_model[1]
predictions = chosen_model[0]
ending_balance_model = model_trading_strategy(initial_balance, predictions, actual_prices)
print(f"Ending Balance for {chosen_model[4]} Strategy: ${ending_balance_model:.2f}")
ending_balance_bah = buy_and_hold(initial_balance, actual_prices)
print("Ending Balance for Buy and Hold Strategy: ${:.2f}".format(round(ending_balance_bah, 2)))
```

After running the simulation on Apple stock, the model predictions were able to outperform the traditional buy and hold strategy by approximately $615. So to answer the question of, "Can we predict the stock market?", the answer is... to an extent. The stock market is an extremely complex thing to try and predict, so being able to confidently say with certainty that you can predict the stock market is farfetched. The strategy I created for utilizing the model predictions is simple and has flaws. Although in this instance it provided an increase in return, it is not guranteed that it will work everytime, for every stock, in every timeframe. However, this analysis proves that machine learning can provide you with an edge in the market, and increase your investment returns.
